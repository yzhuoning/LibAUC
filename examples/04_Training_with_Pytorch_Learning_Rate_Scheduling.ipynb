{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_Training_with_Pytorch_Learning_Rate_Scheduling.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3tYy2PfpYz_"
      },
      "source": [
        "*   Author: Zhuoning Yuan\n",
        "*   Project: https://github.com/yzhuoning/LibAUC\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSR3EPy_n1Cc"
      },
      "source": [
        "# **Installing LibAUC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBQk04JIm6Kb",
        "outputId": "fef35b4f-0763-4c69-fa9e-229d610e8f97"
      },
      "source": [
        "!pip install libauc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: libauc==1.0.7 from file:///content/libauc-1.0.7-py3-none-any.whl in /usr/local/lib/python3.7/dist-packages (1.0.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSmuI7S2n0uu"
      },
      "source": [
        "# **Importing AUC Training Pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0m60hg13nsc4",
        "outputId": "cedbf51e-f40c-4699-d706-8d1293554b0f"
      },
      "source": [
        "from libauc.losses import AUCMLoss\n",
        "from libauc.optimizers import PESG\n",
        "from libauc.models import ResNet20\n",
        "from libauc.datasets import CIFAR10\n",
        "from libauc.datasets import imbalance_generator \n",
        "\n",
        "import torch \n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, images, targets, image_size=32, crop_size=30, mode='train'):\n",
        "       self.images = images.astype(np.uint8)\n",
        "       self.targets = targets\n",
        "       self.mode = mode\n",
        "       self.transform_train = transforms.Compose([                                                \n",
        "                              transforms.ToTensor(),\n",
        "                              transforms.RandomCrop((crop_size, crop_size), padding=None),\n",
        "                              transforms.RandomHorizontalFlip(),\n",
        "                              transforms.Resize((image_size, image_size)),\n",
        "                              ])\n",
        "       self.transform_test = transforms.Compose([\n",
        "                             transforms.ToTensor(),\n",
        "                             transforms.Resize((image_size, image_size)),\n",
        "                              ])\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        target = self.targets[idx]\n",
        "        image = Image.fromarray(image.astype('uint8'))\n",
        "        if self.mode == 'train':\n",
        "            image = self.transform_train(image)\n",
        "        else:\n",
        "            image = self.transform_test(image)\n",
        "        return image, target\n",
        "\n",
        "# paramaters\n",
        "SEED = 123\n",
        "BATCH_SIZE = 128\n",
        "imratio = 0.1\n",
        "lr = 0.1\n",
        "gamma = 500\n",
        "weight_decay = 1e-4\n",
        "margin = 1.0\n",
        "\n",
        "\n",
        "# dataloader \n",
        "(train_data, train_label), (test_data, test_label) = CIFAR10()\n",
        "(train_images, train_labels) = imbalance_generator(train_data, train_label, imratio=imratio, shuffle=True, random_seed=SEED)\n",
        "(test_images, test_labels) = imbalance_generator(test_data, test_label, is_balanced=True,  random_seed=SEED)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(ImageDataset(train_images, train_labels), batch_size=BATCH_SIZE, shuffle=True, num_workers=1, pin_memory=True, drop_last=True)\n",
        "testloader = torch.utils.data.DataLoader( ImageDataset(test_images, test_labels, mode='test'), batch_size=BATCH_SIZE, shuffle=False, num_workers=1,  pin_memory=True)\n",
        "\n",
        "# model \n",
        "model = ResNet20(pretrained=False, num_classes=1)\n",
        "model = model.cuda()\n",
        "\n",
        "# loss & optimizer\n",
        "Loss = AUCMLoss(imratio=imratio)\n",
        "optimizer = PESG(model, \n",
        "                 a=Loss.a, \n",
        "                 b=Loss.b, \n",
        "                 alpha=Loss.alpha, \n",
        "                 imratio=imratio, \n",
        "                 lr=lr, \n",
        "                 gamma=gamma, \n",
        "                 margin=margin, \n",
        "                 weight_decay=weight_decay)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NUM_SAMPLES: [27777], POS:NEG: [2777 : 25000], POS_RATIO: 0.1000\n",
            "NUM_SAMPLES: [10000], POS:NEG: [5000 : 5000], POS_RATIO: 0.5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qouS-m5soBbL"
      },
      "source": [
        "# **Pytorch Learning Rate Scheduling**\n",
        "*   CosineAnnealingLR\n",
        "*   ReduceLROnPlateau\n",
        "*   MultiStepLR\n",
        "\n",
        "\n",
        "\n",
        "Reference: https://pytorch.org/docs/stable/optim.html\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nTXyToIyov6"
      },
      "source": [
        "def reset_model():\n",
        "    # loss & optimizer\n",
        "    Loss = AUCMLoss(imratio=imratio)\n",
        "    optimizer = PESG(model, \n",
        "                    a=Loss.a, \n",
        "                    b=Loss.b, \n",
        "                    alpha=Loss.alpha, \n",
        "                    imratio=imratio, \n",
        "                    lr=lr, \n",
        "                    gamma=gamma, \n",
        "                    margin=margin, \n",
        "                    weight_decay=weight_decay)\n",
        "    return Loss, optimizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7M3g29upT1r"
      },
      "source": [
        "### CosineAnnealingLR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyFWKbrpoBFz"
      },
      "source": [
        "total_epochs = 10\n",
        "Loss, optimizer = reset_model()\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, len(trainloader)*total_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JP8isMj4txc3",
        "outputId": "8e0b09da-c0be-4093-a2ce-c07d7b26d28a"
      },
      "source": [
        "model.train()    \n",
        "for epoch in range(total_epochs):\n",
        "     for i, (data, targets) in enumerate(trainloader):\n",
        "         data, targets  = data.cuda(), targets.cuda()\n",
        "         y_pred = model(data)\n",
        "         loss = Loss(y_pred, targets)\n",
        "         optimizer.zero_grad()\n",
        "         loss.backward()\n",
        "         optimizer.step()\n",
        "         scheduler.step()\n",
        "     print(\"epoch: {}, loss: {:4f}, lr:{:4f}\".format(epoch, loss.item(), optimizer.lr))          "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0, train_loss: 0.089644, lr:0.097575\n",
            "epoch: 1, train_loss: 0.071552, lr:0.090493\n",
            "epoch: 2, train_loss: 0.074371, lr:0.079448\n",
            "epoch: 3, train_loss: 0.067860, lr:0.065520\n",
            "epoch: 4, train_loss: 0.070255, lr:0.050072\n",
            "epoch: 5, train_loss: 0.024033, lr:0.034618\n",
            "epoch: 6, train_loss: 0.053591, lr:0.020669\n",
            "epoch: 7, train_loss: 0.076163, lr:0.009592\n",
            "epoch: 8, train_loss: 0.062752, lr:0.002470\n",
            "epoch: 9, train_loss: 0.063125, lr:0.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZ6_-eT2v44n"
      },
      "source": [
        "### ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNDn1TDMv4PP"
      },
      "source": [
        "total_epochs = 20\n",
        "Loss, optimizer = reset_model()\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n",
        "                                                       patience=3,  \n",
        "                                                       verbose=True, \n",
        "                                                       factor=0.5, \n",
        "                                                       threshold=0.001,\n",
        "                                                       min_lr=0.00001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RojZiIXJwagO",
        "outputId": "2ad6723f-7cb1-4d5c-ecec-ef542c8aa76e"
      },
      "source": [
        "model.train()    \n",
        "for epoch in range(total_epochs):\n",
        "     for i, (data, targets) in enumerate(trainloader):\n",
        "         data, targets  = data.cuda(), targets.cuda()\n",
        "         y_pred = model(data)\n",
        "         loss = Loss(y_pred, targets)\n",
        "         optimizer.zero_grad()\n",
        "         loss.backward()\n",
        "         optimizer.step()\n",
        "     scheduler.step(loss)\n",
        "     print(\"epoch: {}, loss: {:4f}, lr:{:4f}\".format(epoch, loss.item(), optimizer.lr))          "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0, loss: 0.063075, lr:0.100000\n",
            "epoch: 1, loss: 0.106665, lr:0.100000\n",
            "epoch: 2, loss: 0.069563, lr:0.100000\n",
            "epoch: 3, loss: 0.043283, lr:0.100000\n",
            "epoch: 4, loss: 0.107795, lr:0.100000\n",
            "epoch: 5, loss: 0.084268, lr:0.100000\n",
            "epoch: 6, loss: 0.077447, lr:0.100000\n",
            "Epoch     8: reducing learning rate of group 0 to 5.0000e-02.\n",
            "epoch: 7, loss: 0.044456, lr:0.100000\n",
            "epoch: 8, loss: 0.038239, lr:0.050000\n",
            "epoch: 9, loss: 0.049636, lr:0.050000\n",
            "epoch: 10, loss: 0.036171, lr:0.050000\n",
            "epoch: 11, loss: 0.019520, lr:0.050000\n",
            "epoch: 12, loss: 0.037929, lr:0.050000\n",
            "epoch: 13, loss: 0.067369, lr:0.050000\n",
            "epoch: 14, loss: 0.040822, lr:0.050000\n",
            "Epoch    16: reducing learning rate of group 0 to 2.5000e-02.\n",
            "epoch: 15, loss: 0.101739, lr:0.050000\n",
            "epoch: 16, loss: 0.023114, lr:0.025000\n",
            "epoch: 17, loss: 0.000277, lr:0.025000\n",
            "epoch: 18, loss: 0.041810, lr:0.025000\n",
            "epoch: 19, loss: 0.000383, lr:0.025000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ol6mnV8dyHZa"
      },
      "source": [
        "### MultiStepLR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zSK_ENbx8oR"
      },
      "source": [
        "total_epochs = 20\n",
        "Loss, optimizer = reset_model()\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10,15], gamma=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VihFwQ1UyIxm",
        "outputId": "ab5e4101-9698-4828-f7a2-ef2588a965e5"
      },
      "source": [
        "# reset model\n",
        "model.train()    \n",
        "for epoch in range(total_epochs):\n",
        "     for i, (data, targets) in enumerate(trainloader):\n",
        "         data, targets  = data.cuda(), targets.cuda()\n",
        "         y_pred = model(data)\n",
        "         loss = Loss(y_pred, targets)\n",
        "         optimizer.zero_grad()\n",
        "         loss.backward()\n",
        "         optimizer.step()\n",
        "     scheduler.step()\n",
        "     print(\"epoch: {}, loss: {:4f}, lr:{:4f}\".format(epoch, loss.item(), optimizer.lr))          "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0, loss: 0.087777, lr:0.100000\n",
            "epoch: 1, loss: 0.069161, lr:0.100000\n",
            "epoch: 2, loss: 0.074617, lr:0.100000\n",
            "epoch: 3, loss: 0.101814, lr:0.100000\n",
            "epoch: 4, loss: 0.063635, lr:0.100000\n",
            "epoch: 5, loss: 0.013147, lr:0.100000\n",
            "epoch: 6, loss: 0.043657, lr:0.100000\n",
            "epoch: 7, loss: 0.048249, lr:0.100000\n",
            "epoch: 8, loss: 0.067078, lr:0.100000\n",
            "epoch: 9, loss: 0.025596, lr:0.100000\n",
            "epoch: 10, loss: 0.021931, lr:0.010000\n",
            "epoch: 11, loss: 0.016166, lr:0.010000\n",
            "epoch: 12, loss: 0.064753, lr:0.010000\n",
            "epoch: 13, loss: 0.076789, lr:0.010000\n",
            "epoch: 14, loss: 0.035034, lr:0.010000\n",
            "epoch: 15, loss: 0.048091, lr:0.001000\n",
            "epoch: 16, loss: 0.064210, lr:0.001000\n",
            "epoch: 17, loss: 0.033093, lr:0.001000\n",
            "epoch: 18, loss: 0.079196, lr:0.001000\n",
            "epoch: 19, loss: 0.034892, lr:0.001000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
